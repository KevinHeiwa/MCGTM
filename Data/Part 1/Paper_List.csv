When ChatGPT goes rogue: exploring the potential cybersecurity threats of AI-powered conversational chatbots
What Effects Do Large Language Models Have on Cybersecurity
Weaponising chatgpt
Weak-to-Strong Jailbreaking on Large Language Models
Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks
Using Large Language Models for Cybersecurity Capture-The-Flag Challenges and Certification Questions
Using chatgpt to analyze ransomware messages and to predict ransomware threats
"Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities"
Unveiling the Dark Side of ChatGPT: Exploring Cyberattacks and Enhancing User Awareness
Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities
Two Timin': Repairing Smart Contracts With A Two-Layered Approach
Towards Evaluation and Understanding of Large Language Models for Cyber Operation Automation
The new risks chatgpt poses to cybersecurity
The GPT tool for an in-depth analysis on Hawkeye trojan incident
The Evolution of Integrated Advance Persistent Threat and Its Defense Solutions: A Literature Review
The Ethics of Interaction: Mitigating Security Threats in LLMs
The ChatGPT Revolution: How to Simplify Your Work and Life Admin with AI
The Blend of Human Cognition and AI Automation: What Will ChatGPT Do to the Cybersecurity Landscape?
Testing Language Model Agents Safely in the Wild
Spear phishing with large language models
Single-Shot Black-Box Adversarial Attacks Against Malware Detectors: A Causal Language Model Approach
SigIL: A Signature-Based Approach of Malware Detection on Intermediate Language
Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models
Security and Privacy Concerns in ChatGPT
Security and Privacy Challenges of Large Language Models: A Survey
Security and Authenticity of AI-generated code
Search and Retrieval in Semantic-Structural Representations of Novel Malware
Sc-safety: A multi-round open-ended question adversarial safety benchmark for large language models in chinese
"Robustness, security, privacy, explainability, efficiency, and usability of large language models for code"
Revolutionizing Cyber Threat Detection with Large Language Models: A privacy-preserving BERT-based Lightweight Model for IoT/IIoT Devices
Research on Multiparty Participation Collaborative Supervision Strategy of AIGC
Ratgpt: Turning online llms into proxies for malware attacks
Query-Relevant Images Jailbreak Large Multi-Modal Models
"PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety"
Pop quiz! can a large language model help with reverse engineering
OWL: A Large Language Model for IT Operations
Open-source can be dangerous: On the vulnerability of value alignment in open-source LLMs
Opening A Pandora's Box: Things You Should Know in the Era of Custom GPTs
On the Vulnerabilities of Text-to-SQL Models
On the risk of misinformation pollution with large language models
On Hardware Security Bug Code Fixes By Prompting Large Language Models
Ocassionally Secure: A Comparative Analysis of Code Generation Assistants
Multi-step Jailbreaking Privacy Attacks on ChatGPT
Multilingual jailbreak challenges in large language models
Multilingual jailbreak challenges in large language models
Mining Temporal Attack Patterns from Cyberthreat Intelligence Reports
Metamorphic Malware Evolution: The Potential and Peril of Large Language Models
MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots
Malware Detection with Artificial Intelligence: A Systematic Literature Review
Machiavellianism and Security: Leveraging Queries at LLMs for Black Hat Operations
Maatphor: Automated Variant Analysis for Prompt Injection Attacks
Llm-Tikg: Threat Intelligence Knowledge Graph Construction Utilizing Large Language Model
Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models
Large language models for code analysis: Do llms really do their job?
Large Language Models and Security
Large Language Models and Computer Security
Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study
Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation
Investigating ChatGPT and cybersecurity: A perspective on topic modeling and sentiment analysis
Impacts and risk of generative ai technology on cyber defense
Impact of big data analytics and chatgpt on cybersecurity
Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications
How well does llm generate security tests
How well can machine-generated texts be identified and can language models be trained to avoid identification?
How chatgpt is revolutionizing ransomware attacks and what your business can do
GPThreats-3: Is Automatic Malware Generation a Threat? 
Getting pwn'd by ai: Penetration testing with large language models
Generative Neural Networks as a Tool for Web Applications Penetration Testing
Generative AI-Driven Approach to Converting Numerical Code into Mathematical Functions
GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models
From text to mitre techniques: Exploring the malicious use of large language models for generating cyber attack payloads
From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy
Figstep: Jailbreaking large vision-language models via typographic visual prompts
Extracting Actionable Cyber Threat Intelligence from Twitter Stream
Exploring the Dark Side of AI: Advanced Phishing Attack Design and Deployment Using ChatGPT
Exploiting novel gpt-4 apis
Exploiting Large Language Models (LLMs) through Deception Techniques and Persuasion Principles
Experienced and novice cybercriminals are using chatgpt to create hacking tools and code
Evolutionary Based Transfer Learning Approach to Improving Classification of Metamorphic Malware
"Evaluating LLMs for Privilege-Escalation Scenarios"
Evaluating Large Language Models in Ransomware Negotiation: A Comparative Analysis of ChatGPT and Claude
Ethical Considerations and Policy Implications for Large Language Models: Guiding Responsible Development and Deployment
Enhancing Code Obfuscation Techniques: Exploring the Impact of Artificial Intelligence on Malware Detection
Enabling programming thinking in large language models toward code generation
Embracing the Generative AI Revolution: Advancing Tertiary Education in Cybersecurity with GPT
EM-BERT: A Language Model Based Method to Detect Encrypted Malicious Network Traffic
Efficient Ransomware Detection via Portable Executable File Image Analysis By LLaMA-7b
Do you trust your model? emerging malware threats in the deep learning ecosystem
Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content
Divas: An llm-based end-to-end framework for soc security analysis and policy-based protec-tion
Detecting Scams Using Large Language Models
Detecting Phishing Sites Using ChatGPT
Demystifying rce vulnerabilities in llm-integrated apps
Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing
Defending chatgpt against jailbreak attack via self-reminder
Cybersecurity Issues in Generative AI
Cybercrime and Privacy Threats of Large Language Models
Controlling large language models to generate secure and vulnerable code
Comparing Signature Detection of Convolutional Neural Network in Low-Level and Large Language Model in High-Level Programming Language
Cognitive overload: Jailbreaking large language models with overloaded logical thinkin
Checkpoint: cybercriminals bypass ChatGPT restrictions to generate malicious content.
ChatSpamDetector: Leveraging Large Language Models for Effective Phishing Email Detection
"ChatGPT’s Security Risks and Benefits: Offensive and Defensive Use-Cases, Mitigation Measures, and Future Implications"
ChatGPT: The Curious Case of Attack Vectors’ Supply 
ChatGPT: A Threat Against the CIA Triad of Cyber Security
"ChatGPT in Education, Healthcare, and Cybersecurity: Opportunities and Challenges
"
ChatGPT for Computational Social Systems: From Conversational Applications to Human-Oriented Operating Systems
"Chatbots to ChatGPT in a Cybersecurity Space: Evolution, Vulnerabilities, Attacks, Challenges, and Future Recommendations"
Chatbots in a botnet world.
Can large language models find and fix vulnerable software?
"Bypassing antivirus detection: old-school malware, new tricks"
Binary code summarization: Benchmarking chatgpt/gpt-4 and other large language models
Being a Bad Influence on the Kids: Malware Generation in Less Than Five Minutes Using ChatGPT
Backdooring instruction-tuned large language models with virtual prompt injection
Backdoor activation attack: Attack large language models using activation steering for safety-alignment
AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks
Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions
Are Large Language Models Really Robust to Word-Level Perturbations?
An Attacker’s Dream? Exploring the Capabilities of ChatGPT for Developing Malware
AMSI-Based Detection of Malicious PowerShell Code Using Contextual Embeddings
Adversarial attacks and defenses in large language models: Old and new threats
AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns
"A survey on ChatGPT: AI-generated contents, challenges, and solutions"
"A Survey of Large Language Models in Cybersecurity
"
A study on robustness and reliability of large language model code generation
A security risk taxonomy for large language models
A Dimensional Perspective Analysis on the Cybersecurity Risks and Opportunities of ChatGPT-Like Information Systems
A Cross-Language Investigation into Jailbreak Attacks in Large Language Models
