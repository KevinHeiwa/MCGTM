Web Site & News
https://zvelo.com/malicious-ai-the-rise-of-dark-llms/
https://zvelo.com/ai-powered-malware-holds-potential-for-extreme-consequences/
https://zapier.com/blog/ai-security-risks/
https://www.zdnet.com/article/people-are-already-trying-to-get-chatgpt-to-write-malware/
https://www.zdnet.com/article/as-ai-agents-spread-so-do-the-risks-scholars-say/
https://www.wwt.com/blog/preparing-for-ransomware-in-the-age-of-generative-ai
https://www.washingtonpost.com/politics/2023/01/26/yes-chatgpt-can-write-malware-code-not-well/
https://www.vnetwork.vn/en-US/news/hacker-loi-dung-chatgpt-tao-email-lua-dao/
https://www.tweaktown.com/news/96643/researchers-create-never-before-seen-cyberattack-using-generative-ai/index.html
https://www.trendmicro.com/en_us/research/23/k/a-closer-look-at-chatgpt-s-role-in-automated-malware-creation.html
https://www.trendmicro.com/en_us/devops/23/e/chatgpt-security-vulnerabilities.html
https://www.theregister.com/2023/01/06/chatgpt_cybercriminals_malicious_code/
https://www.thehindu.com/sci-tech/technology/chatgpt-helping-hackers-write-malware-codes/article66349507.ece
https://www.techtarget.com/searchenterpriseai/tip/Improve-AI-security-by-red-teaming-large-language-models
https://www.techtarget.com/searchenterpriseai/tip/Explore-mitigation-strategies-for-LLM-vulnerabilities
https://www.techspot.com/news/102121-security-researchers-prove-they-can-exploit-chatbot-systems.html
https://www.techpolicy.press/studying-black-market-for-large-language-models-researchers-find-openai-models-power-malicious-services/
https://www.techopedia.com/12-practical-large-language-model-llm-applications
https://www.technologyreview.com/2023/04/03/1070893/three-ways-ai-chatbots-are-a-security-disaster/
https://www.synack.com/pentesting-ai-and-large-language-models/
https://www.symmetry-systems.com/blog/unlocking-the-potential-of-generative-ai-for-cybersecurity/
https://www.standard.net/lifestyle/home_and_family/2024/mar/06/tech-matters-security-tips-for-artificial-intelligence-tools/
https://www.splunk.com/en_us/blog/security/paws-in-the-pickle-jar-risk-vulnerability-in-the-model-sharing-ecosystem.html
https://www.spiceworks.com/tech/artificial-intelligence/guest-article/strategies-for-generative-ai-attacks/
https://www.spiceworks.com/it-security/cyber-risk-management/news/generative-ai-llm-used-by-apt-groups/
https://www.soitron.com/malicious-code-injections/
https://www.securityweek.com/malicious-gpt-can-phish-credentials-exfiltrate-them-to-external-server-researcher/
https://www.securityweek.com/chatgpt-hallucinations-can-be-exploited-to-distribute-malicious-code-packages/
https://www.securitymagazine.com/articles/100096-fighting-the-dark-side-of-generative-ai
https://www.secureworld.io/industry-news/fraudgpt-malicious-ai-bot
https://www.scmagazine.com/native/and-i-shall-call-it-mini-me-gpt-using-large-language-models-to-classify-the-uncharted-web
https://www.schneier.com/blog/archives/2023/03/prompt-injection-attacks-on-large-language-models.html
https://www.sangfor.com/blog/cybersecurity/chatgpt-malware-a-new-threat-in-cybersecurity
https://www.sailpoint.com/identity-library/how-ai-and-machine-learning-are-improving-cybersecurity/
https://www.safeguardcyber.com/blog/security/large-language-models-in-cybersecurity
https://www.reversinglabs.com/blog/owasp-readies-top-10-for-llm-app-sec-risk-what-your-software-team-needs-to-know
https://www.rappler.com/technology/cybercriminals-bypass-openai-chatgpt-restrictions/
https://www.pymnts.com/artificial-intelligence-2/2024/fbi-sounds-alarm-on-ai-driven-infrastructure-hacking/
https://www.propertycasualty360.com/2024/03/08/conned-by-chatgpt-the-growing-risks-of-ai-powered-cyber-attacks/?slreturn=20240208191246
https://www.private-ai.com/2023/01/18/addressing-privacy-and-the-gdpr-in-chatgpt-and-large-language-models/
https://www.pluralsight.com/resources/blog/data/chatgpt-writing-viruses
https://www.pcrisk.com/removal-guides/27459-gpt-ransomware
https://www.pcmag.com/news/cybercriminals-using-chatgpt-to-build-hacking-tools-write-code
https://www.paloaltonetworks.com/blog/2023/07/llm-in-the-cloud/
https://www.paloaltonetworks.co.uk/cybersecurity-perspectives/a-new-era-of-cybersecurity-with-ai
https://www.paloaltonetworks.co.uk/blog/2023/07/llm-in-the-cloud/
https://www.packetlabs.net/posts/ai-platforms-used-to-craft-malicious-code/
https://www.orfonline.org/expert-speak/vulnerabilities-in-large-language-models
https://www.nextplatform.com/2023/04/26/keeping-large-language-models-from-running-off-the-rails/
https://www.newscientist.com/article/2418201-gpt-4-developer-tool-can-hack-websites-without-human-help/
https://www.newscientist.com/article/2399370-chatgpt-wrote-code-that-can-make-databases-leak-sensitive-information/
https://www.netskope.com/blog/understanding-the-risks-of-prompt-injection-attacks-on-chatgpt-and-other-language-models
https://www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat
https://www.moveworks.com/us/en/resources/blog/risks-of-deploying-llms-in-your-enterprise
https://www.microsoft.com/en-us/security/blog/2024/02/14/staying-ahead-of-threat-actors-in-the-age-of-ai/
https://www.marktechpost.com/2024/01/16/anthropic-ai-experiment-reveals-trained-llms-harbor-malicious-intent-defying-safety-measures/
https://www.malwarebytes.com/cybersecurity/basics/risks-of-ai-in-cyber-security
https://www.malwarebytes.com/blog/news/2023/04/chatgpt-creates-not-so-secure-code-study-finds
https://www.malwarebytes.com/blog/news/2023/02/jailbreaking-large-language-models-like-chatgp-while-we-still-can
https://www.linkedin.com/pulse/owasp-top-10-large-language-model-applications-guilherme-junior
https://www.linkedin.com/pulse/malware-2023-chat-gpt-other-concerns-datcomllc
https://www.itprotoday.com/software-development/why-prompt-injection-threat-large-language-models
https://www.infosectrain.com/blog/ai-at-risk-owasp-top-10-critical-vulnerabilities-for-large-language-models-llms/
https://www.information-age.com/large-language-models-in-cybersecurity-123507710/
https://www.indiatoday.in/technology/news/story/hackers-are-using-chatgpt-to-create-malware-to-steal-your-money-2319565-2023-01-10
https://www.impactmybiz.com/blog/how-ai-generated-malware-is-changing-cybersecurity/
https://www.ibm.com/blog/open-source-large-language-models-benefits-risks-and-types/
https://www.hyas.com/blog/future-proofing-cybersecurity-why-hyas-built-ai-generated-malware
https://www.hyas.com/blog/blackmamba-using-ai-to-generate-polymorphic-malware
https://www.hhs.gov/sites/default/files/ai-for-malware-development-analyst-note.pdf
https://www.helpnetsecurity.com/2024/01/10/llm-vulnerabilities-risk/
https://www.helpnetsecurity.com/2023/12/07/automated-jailbreak-llms/
https://www.helpnetsecurity.com/2023/04/03/machine-learning-malware/
https://www.hackread.com/openais-chatgpt-polymorphic-malware/
https://www.guidepointsecurity.com/blog/ensuring-the-security-of-large-language-models/
https://www.gptguard.ai/blog/llm-vulnerabilities
https://www.getastra.com/blog/security-audit/owasp-large-language-model-llm-top-10/
https://www.genetec.com/blog/cybersecurity/the-implications-of-large-language-models-in-physical-security
https://www.freecodecamp.org/news/large-language-models-and-cybersecurity/
https://www.fortinet.com/blog/industry-trends/ai-and-security-practitioner
https://www.fortinet.com/blog/ciso-collective/power-and-limitations-of-ai-in-cybersecurity
https://www.forcepoint.com/blog/x-labs/zero-day-exfiltration-using-chatgpt-prompts
https://www.forcepoint.com/blog/insights/ai-cyber-threat-beyond-hype
https://www.forbes.com/sites/thomasbrewster/2023/03/16/gpt-4-could-help-stupid-hackers-become-good-cybercriminals/?sh=12ad14d622cf
https://www.forbes.com/sites/forbestechcouncil/2023/10/27/how-to-defend-against-malicious-llm-cyberattacks/
https://www.forbes.com/sites/forbestechcouncil/2023/06/30/10-ways-cybercriminals-can-abuse-large-language-models/?sh=636005a4304c
https://www.forbes.com/sites/forbes-personal-shopper/article/best-places-to-buy-contacts-online/?sh=18268a10e16c
https://www.forbes.com/sites/daveywinder/2023/02/03/does-chatgpt-pose-a-cybersecurity-threat-heres-the-ai-bots-answer/?sh=41891500505d
https://www.forbes.com/sites/bernardmarr/2023/01/25/how-dangerous-are-chatgpt-and-natural-language-technology-for-cybersecurity/?sh=198ac22d4aa6
https://www.europol.europa.eu/media-press/newsroom/news/criminal-use-of-chatgpt-cautionary-tale-about-large-language-models
https://www.esecurityplanet.com/threats/gpt4-security/
https://www.esecurityplanet.com/threats/chatgpt-malware/
https://www.endorlabs.com/learn/reviewing-malware-with-llms-openai-vs-vertex-ai
https://www.endorlabs.com/learn/llm-assisted-malware-review-ai-and-humans-join-forces-to-combat-malware
https://www.edgemiddleeast.com/security/fake-access-to-malicious-ai-tool-wormgpt-for-sale-on-dark-web
https://www.digitaltrends.com/computing/chatgpt-hack-allows-chatbot-to-generate-malware/
https://www.dig.security/glossary/large-language-model-llm-security
https://www.deepinstinct.com/blog/chatgpt-and-malware-making-your-malicious-wishes-come-true
https://www.dazeddigital.com/life-culture/article/60376/1/what-is-worm-gpt-the-new-ai-behind-the-recent-wave-of-cyberattacks
https://www.darkreading.com/vulnerabilities-threats/bad-actors-will-use-large-language-models-defenders-can-too
https://www.darkreading.com/threat-intelligence/chatgpt-could-create-polymorphic-malware-researchers-warn
https://www.darkreading.com/cyberattacks-data-breaches/wormgpt-cybercrime-tool-heralds-an-era-of-ai-malware-v-ai-defenses
https://www.darkreading.com/cyberattacks-data-breaches/attackers-are-already-exploiting-chatgpt-to-write-malicious-code
https://www.darkreading.com/application-security/hugging-face-ai-platform-100-malicious-code-execution-models
https://www.darkreading.com/application-security/gpt-based-malware-trains-dark-web
https://www.dacbeachcroft.com/en/What-we-think/the-ethics-of-ai-the-cyber-risks-posed-by-chat-gpt
https://www.cybertalk.org/2023/06/02/5-ways-chatgpt-and-llms-can-advance-cyber-security/
https://www.cybertalk.org/2023/01/09/openais-chatgpt-bot-the-hazardous-malware-that-it-easily-spits-out/
https://www.cyberghostvpn.com/en_US/privacyhub/chatgpt-malware/
https://www.cyberdefensemagazine.com/do-highly-intelligent-language-models-pose-a-cyber-threat/
https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware
https://www.coalfire.com/the-coalfire-blog/owasp-top-10-for-large-language-model-applications
https://www.cnbc.com/2023/11/28/ai-like-chatgpt-is-creating-huge-increase-in-malicious-phishing-email.html
https://www.cloudflare.com/zh-cn/the-net/vulnerable-llm-ai/
https://www.cio.com/article/656762/exploring-the-pros-and-cons-of-cloud-based-large-language-models.html
https://www.cbc.ca/news/science/chatgpt-cybercriminals-warning-1.6710854
https://www.carol-anderson.com/blog/large-language-models-are-vulnerable-to-prompt-injection-attacks
https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/AI-in-lLanguage-processing.pdf?__blob=publicationFile&v=2
https://www.bleepingcomputer.com/news/security/uk-says-ai-will-empower-ransomware-over-the-next-two-years/
https://www.bleepingcomputer.com/news/security/trojan-puzzle-attack-trains-ai-assistants-into-suggesting-malicious-code/
https://www.axios.com/2023/12/07/meta-purple-llama-llm-cybersecurity-generative-ai
https://www.axios.com/2023/01/10/hackers-chatgpt-malware-cybercrime-ai
https://www.atb.com/personal/good-advice/banking-and-security-tips/how-fraudsters-are-using-chat-gpt-and-other-ai-tools-to-create-scams/
https://www.aspistrategist.org.au/malicious-ai-arrives-on-the-dark-web/
https://www.analyticsinsight.net/how-to-run-the-chatgpt-locally-using-a-docker-desktop/
https://www.americanbanker.com/news/how-fraudsters-are-exploiting-and-retraining-large-language-models
https://www.akaike.ai/resources/guarding-the-gates-addressing-security-and-privacy-challenges-in-large-language-model-ai-systems
https://typeset.io/questions/how-do-machine-learning-algorithms-contribute-to-efficient-1fhkfmqede
https://thesecmaster.com/the-dark-side-of-ai-wormgpt-a-malicious-gpt-tool-for-cybercriminals/
https://thehackernews.com/2024/03/over-100-malicious-aiml-models-found-on.html
https://thehackernews.com/2023/07/wormgpt-new-ai-tool-allows.html
https://theaiobserverx.substack.com/p/the-dark-side-of-llms-addressing
https://techinformed.com/dark-subscriptions-the-rise-of-fraudgpt/
https://techhq.com/2024/03/hugging-face-safetensors-vulnerable-to-supply-chain-attacks/
https://techhq.com/2023/07/chatgpt-malware-how-do-hackers-use-openai-bot-to-compromise-victims/
https://techcrunch.com/2023/08/01/theres-no-reason-to-panic-over-wormgpt/
https://startups.microsoft.com/blog/pitfalls-to-avoid-when-using-ai-to-analyze-code/
https://socradar.io/owasp-top-10-or-llms/
https://socradar.io/every-1-of-3-ai-generated-code-is-vulnerable-exploring-insights-with-cyberseceval/
https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/
https://siliconangle.com/2023/09/26/security-threats-ai-large-language-models-mounting-spurring-efforts-fix/
https://siliconangle.com/2023/07/03/cybersecurity-ai-age-power-promise-peril/
https://siliconangle.com/2023/07/03/ai-large-language-models-can-help-cybersecurity-firms-improve-services/
https://services.google.com/fh/files/blogs/google_ai_red_team_digital_final.pdf
https://securityintelligence.com/posts/unmasking-hypnotized-ai-hidden-risks-large-language-models/
https://securityintelligence.com/articles/back-to-basics-better-security-ai/
https://securityboulevard.com/2024/03/5-ways-to-prevent-prompt-injection-attacks/
https://research.checkpoint.com/2022/opwnai-ai-that-can-save-the-day-or-hack-it-away/
https://research.aimultiple.com/llm-security-tools/
https://news.sophos.com/en-us/2023/11/28/cybercriminals-cant-agree-on-gpts/
https://news.sophos.com/en-us/2023/06/22/using-large-language-models-classify-uncharted-web/
https://networkassured.com/security/all-chatgpt-cybersecurity-risks-attacks/
https://medium.com/@b42labs/llm-meets-malware-starting-the-era-of-autonomous-threat-e8c5827ccc85
https://me.pcmag.com/en/ai/22398/new-malware-worm-can-poison-chatgpt-gemini-powered-assistants
https://infosecwriteups.com/securing-large-language-models-llms-in-your-organization-mitigating-security-and-privacy-risks-9a70b5936906
https://indianexpress.com/article/technology/chatgpt-phishing-email-malware-malicious-code-8370730/
https://inderbarara.medium.com/darkside-of-large-language-models-llms-cd3e074b9897
https://inconsult.com.au/publication/can-chatgpt-be-exploited-to-benefit-hackers/
https://hiddenlayer.com/research/the-dark-side-of-large-language-models-2/
https://hiddenlayer.com/research/the-dark-side-of-large-language-models/
https://heimdalsecurity.com/blog/malicious-generative-ai-tools-solution/
https://healthitsecurity.com/news/hc3-warns-healthcare-of-ais-use-in-malware-development
https://grumpygrace.dev/posts/top-10-sec-llm/
https://gradientflow.com/large-language-models-in-cybersecurity/
https://gizmodo.com/chatgpt-ai-polymorphic-malware-computer-virus-cyber-1850012195
https://github.com/tenable/awesome-llm-cybersecurity-tools
https://gbhackers.com/malicious-ads-on-bing-chat/
https://gbhackers.com/chatgpt-sale-on-dark-web/
https://futurism.com/researchers-create-ai-malware
https://developer.nvidia.com/blog/nvidia-enables-trustworthy-safe-and-secure-large-language-model-conversational-systems/
https://bdtechtalks.com/2024/01/17/anthropic-llm-backdoor/
https://bdtechtalks.com/2023/12/07/chatgpt-malware/
https://any.run/cybersecurity-blog/will-ai-be-the-start-of-super-malware/
